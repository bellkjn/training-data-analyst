{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "189c4dec",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4c490888",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('refined_used_car.csv')\n",
    "LABEL_COLUMN = 'Price'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9e3ef7a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def features_and_labels(row_data):\n",
    "    \"\"\"Splits features and labels from feature dictionary.\n",
    "\n",
    "    Args:\n",
    "        row_data: Dictionary of CSV column names and tensor values.\n",
    "    Returns:\n",
    "        Dictionary of feature tensors and label tensor.\n",
    "    \"\"\"\n",
    "    label = row_data.pop(LABEL_COLUMN)\n",
    "\n",
    "    return row_data, label  # features, label\n",
    "\n",
    "\n",
    "def load_dataset(pattern, batch_size=1, mode=tf.estimator.ModeKeys.EVAL):\n",
    "    \"\"\"Loads dataset using the tf.data API from CSV files.\n",
    "\n",
    "    Args:\n",
    "        pattern: str, file pattern to glob into list of files.\n",
    "        batch_size: int, the number of examples per batch.\n",
    "        mode: tf.estimator.ModeKeys to determine if training or evaluating.\n",
    "    Returns:\n",
    "        `Dataset` object.\n",
    "    \"\"\"\n",
    "    # TODO: Make a CSV dataset\n",
    "    dataset = tf.data.experimental.make_csv_dataset(pattern, batch_size) #, DEFAULTS)\n",
    "\n",
    "    # TODO: Map dataset to features and label\n",
    "    dataset = dataset.map(features_and_labels)  # features, label\n",
    "\n",
    "    # Shuffle and repeat for training\n",
    "    if mode == tf.estimator.ModeKeys.TRAIN:\n",
    "        dataset = dataset.shuffle(buffer_size=1000).repeat()\n",
    "\n",
    "    # Take advantage of multi-threading; 1=AUTOTUNE\n",
    "    dataset = dataset.prefetch(buffer_size=1)\n",
    "\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "825577c2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0c26c01d",
   "metadata": {},
   "outputs": [],
   "source": [
    "NUMERIC_COLUMNS = [\n",
    " 'Mileage',\n",
    " 'Mpg',\n",
    "]\n",
    "\n",
    "CATEGORICAL_COLUMNS = [\n",
    " 'Transmission',\n",
    " 'FuelType',\n",
    " 'Year',\n",
    " 'EngineSize',\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f575fca6",
   "metadata": {},
   "outputs": [],
   "source": [
    "CATEGORIES = {\n",
    "    'Transmission': ['Automatic', 'Manual', 'Semi-Auto', 'Other'], 'FuelType': ['Petrol', 'Hybrid', 'Diesel', 'Other', 'Electric'], \n",
    "    'Year': [2005, 2017, 2016, 2011, 2018, 2012, 2019, 2020, 2014, 2015, 2006, 2010, 2004, 2008, 2013, 2007, 2009, 2003, 2001, 2002, 1998, 2000, 1997, 1999, 1996, 1991, 1995], \n",
    "    'EngineSize': [1.8, 2.1, 5.5, 4.0, 6.2, 3.5, 2.0, 1.5, 3.0, 1.2, 1.6, 1.4, 1.7, 2.5, 4.7, 1.3, 2.2, 2.9, 0.6, 2.3, 0.8, 1.0, 6.0, 3.2, 4.4, 5.0, 2.7, 3.7, 5.4, 2.8, 1.1, 1.9, 2.4, 4.2, 4.5, 3.6, 2.6, 6.6, 5.2, 4.1, 6.3]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "cc676b1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_categorical(name, voc_list):\n",
    "    cat = tf.feature_column.categorical_column_with_vocabulary_list(name, voc_list)\n",
    "    return tf.feature_column.indicator_column(cat)\n",
    "\n",
    "def create_feature_columns(nembeds):\n",
    "    \"\"\"Creates wide and deep dictionaries of feature columns from inputs.\n",
    "\n",
    "    Args:\n",
    "        nembeds: int, number of dimensions to embed categorical column down to.\n",
    "    Returns:\n",
    "        Wide and deep dictionaries of feature columns.\n",
    "    \"\"\"\n",
    "    # TODO: Create deep feature columns for numeric features\n",
    "    deep_fc = {\n",
    "        colname: tf.feature_column.numeric_column(colname) for colname in NUMERIC_COLUMNS\n",
    "    }\n",
    "\n",
    "    # TODO: Create wide feature columns for categorical features\n",
    "    wide_fc = {\n",
    "        colname: get_categorical(colname, list(CATEGORIES[colname])) for colname in CATEGORICAL_COLUMNS\n",
    "    }\n",
    "\n",
    "#     # TODO: Bucketize the float fields. This makes them wide\n",
    "#     age_bucket = tf.feature_column.bucketized_column(source_column=deep_fc['mother_age'],\n",
    "#                                                     boundaries=np.arange(15, 45, 1).tolist())\n",
    "#     wide_fc['age_bucket'] = tf.feature_column.indicator_column(age_bucket)\n",
    "\n",
    "#     gestation_bucket = tf.feature_column.bucketized_column(source_column=deep_fc['gestation_weeks'],\n",
    "#                                                     boundaries=np.arange(17, 47, 1).tolist())\n",
    "#     wide_fc['gestation_bucket'] = tf.feature_column.indicator_column(gestation_bucket)\n",
    "\n",
    "#     # TODO: Cross all the wide cols, have to do the crossing before we one-hot\n",
    "#     crossed = tf.feature_column.crossed_column([age_bucket, gestation_bucket], 1000)\n",
    "\n",
    "#     # TODO: Embed cross and add to deep feature columns\n",
    "#     deep_fc['crossed'] = tf.feature_column.embedding_column(crossed, dimension=nembeds)\n",
    "\n",
    "    return wide_fc, deep_fc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "90c757a5",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "column_name: EngineSize vocabulary dtype must be string or integer. dtype: <dtype: 'float64'>.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-14-8820ffeb20b8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mcreate_feature_columns\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-13-d3664764c264>\u001b[0m in \u001b[0;36mcreate_feature_columns\u001b[0;34m(nembeds)\u001b[0m\n\u001b[1;32m     18\u001b[0m     \u001b[0;31m# TODO: Create wide feature columns for categorical features\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m     wide_fc = {\n\u001b[0;32m---> 20\u001b[0;31m         \u001b[0mcolname\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mget_categorical\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcolname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mCATEGORIES\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcolname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mcolname\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mCATEGORICAL_COLUMNS\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m     }\n\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-13-d3664764c264>\u001b[0m in \u001b[0;36m<dictcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     18\u001b[0m     \u001b[0;31m# TODO: Create wide feature columns for categorical features\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m     wide_fc = {\n\u001b[0;32m---> 20\u001b[0;31m         \u001b[0mcolname\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mget_categorical\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcolname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mCATEGORIES\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcolname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mcolname\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mCATEGORICAL_COLUMNS\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m     }\n\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-13-d3664764c264>\u001b[0m in \u001b[0;36mget_categorical\u001b[0;34m(name, voc_list)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mget_categorical\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvoc_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0mcat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfeature_column\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcategorical_column_with_vocabulary_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvoc_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfeature_column\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindicator_column\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mcreate_feature_columns\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnembeds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/feature_column/feature_column_v2.py\u001b[0m in \u001b[0;36mcategorical_column_with_vocabulary_list\u001b[0;34m(key, vocabulary_list, dtype, default_value, num_oov_buckets)\u001b[0m\n\u001b[1;32m   1849\u001b[0m           num_oov_buckets, key))\n\u001b[1;32m   1850\u001b[0m   fc_utils.assert_string_or_int(\n\u001b[0;32m-> 1851\u001b[0;31m       vocabulary_dtype, prefix='column_name: {} vocabulary'.format(key))\n\u001b[0m\u001b[1;32m   1852\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mdtype\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1853\u001b[0m     \u001b[0mdtype\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvocabulary_dtype\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/feature_column/utils.py\u001b[0m in \u001b[0;36massert_string_or_int\u001b[0;34m(dtype, prefix)\u001b[0m\n\u001b[1;32m     56\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mdtype\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mdtypes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstring\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;32mnot\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_integer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m     raise ValueError(\n\u001b[0;32m---> 58\u001b[0;31m         '{} dtype must be string or integer. dtype: {}.'.format(prefix, dtype))\n\u001b[0m\u001b[1;32m     59\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: column_name: EngineSize vocabulary dtype must be string or integer. dtype: <dtype: 'float64'>."
     ]
    }
   ],
   "source": [
    "create_feature_columns(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f20e28a0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a0426be",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "name": "tf2-gpu.2-1.m69",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/tf2-gpu.2-1:m69"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

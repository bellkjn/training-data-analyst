{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "34ae3f3a",
   "metadata": {},
   "source": [
    "# training-data-analyst/courses/machine_learning/deepdive2/building_production_ml_systems"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb28b3ff",
   "metadata": {},
   "source": [
    "### set project and region in google cloud environment "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c727ee2",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "gcloud config set project $PROJECT\n",
    "gcloud config set compute/region $REGION"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2f9fc2d",
   "metadata": {},
   "source": [
    "### Create BigQuery tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef0e796c",
   "metadata": {},
   "outputs": [],
   "source": [
    "bq = bigquery.Client(project = PROJECT)\n",
    "dataset = bigquery.Dataset(bq.dataset(\"taxifare\"))\n",
    "\n",
    "try:\n",
    "    bq.create_dataset(dataset)\n",
    "    print(\"Dataset created\")\n",
    "except:\n",
    "    print(\"Dataset already exists\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbd8b43b",
   "metadata": {},
   "source": [
    "### Extracting training data to csv file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5b4cb59",
   "metadata": {},
   "outputs": [],
   "source": [
    "echo \"Extracting training data to $OUTDIR\"\n",
    "bq --location=US extract \\\n",
    "   --destination_format CSV  \\\n",
    "   --field_delimiter \",\" --noprint_header \\\n",
    "   taxifare.feateng_training_data \\\n",
    "   $OUTDIR/taxi-train-*.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5e25e36",
   "metadata": {},
   "source": [
    "### google storage command"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a801d79",
   "metadata": {},
   "outputs": [],
   "source": [
    "!gsutil cat gs://$BUCKET/taxifare/data/taxi-train-000000000000.csv | head -2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4837626f",
   "metadata": {},
   "outputs": [],
   "source": [
    "!gsutil ls gs://$BUCKET/taxifare/data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48a21660",
   "metadata": {},
   "source": [
    "### Jupyter notebook에서 파일 쓰기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd64f01d",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile {TARGET_FILENAME}\n",
    "{CONTENT}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43a235db",
   "metadata": {},
   "source": [
    "### create dataset from csv files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54dfd1cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = tf.data.experimental.make_csv_dataset(\n",
    "    file_pattern=pattern,\n",
    "    batch_size=batch_size,\n",
    "    column_names=CSV_COLUMNS,\n",
    "    column_defaults=DEFAULTS,\n",
    "    num_epochs=num_repeat,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ff6b2a8",
   "metadata": {},
   "source": [
    "### caching dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aaa66eb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.prefetch(1)  # AUTOTUNE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63a2b5dd",
   "metadata": {},
   "source": [
    "### dataset link to map function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6919ab0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.map(__function_name__)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68bf69c2",
   "metadata": {},
   "source": [
    "### about @tf.function decorator\n",
    "\n",
    "@tf.function는 Python 함수를 그래프로 변환해준다. 그래프 최적화(Graph Optimization) 는 만약 동일한 연산이 여기저기서 반복되는 경우 해당 연산 결과를 캐쉬(cache)로 저장해서 사용함으로써 동일 연산이 반복적으로 일어나지 않도록 한다거나, 복잡한 연산의 경우 다수의 장비에서 병렬처리(parallel on multiple devices)를 하여 연산을 빠르게 수행할 수 있도록 하여 성능을 최적화해준다.\n",
    "\n",
    "출처: [R, Python 분석과 프로그래밍의 친구 (by R Friend)](https://rfriend.tistory.com/555)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84d7204b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dayofweek(s):\n",
    "    ts = parse_datetime(s)\n",
    "    return DAYS[ts.weekday()]\n",
    "\n",
    "@tf.function\n",
    "def dayofweek(ts_in):\n",
    "    return tf.map_fn(\n",
    "        lambda s: tf.py_function(get_dayofweek, inp=[s], Tout=tf.string),\n",
    "        ts_in\n",
    "    )\n",
    "\n",
    "# @tf.function\n",
    "# def dayofweek(ts_in):\n",
    "#     return tf.py_function(get_dayofweek, inp=[ts_in], Tout=tf.string)\n",
    "\n",
    "# @tf.function\n",
    "# def dayofweek(ts_in):\n",
    "#     return get_dayofweek(ts_in)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07f54fdf",
   "metadata": {},
   "source": [
    "### about tf.map_fn, tf.py_function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33757289",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "20b8bd6c",
   "metadata": {},
   "source": [
    "### Usage of tf.io.gfile\n",
    "\n",
    "The difference is that you can specify URI schemes to use other filesystems (e.g., gs:// for GCS, s3:// for S3, etc.), if they are supported. Using file:// as an example, we have:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edeb3c73",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"/tmp/x\", \"w\") as f:\n",
    "  f.write(\"asdf\")\n",
    "\n",
    "with tf.io.gfile.GFile(\"/tmp/x\") as f:\n",
    "  f.read()\n",
    "\n",
    "with tf.io.gfile.GFile(\"file:///tmp/x\", \"w\") as f:\n",
    "  f.write(\"qwert\")\n",
    "  f.write(\"asdf\")\n",
    "tf.io.gfile.GFile(\"file:///tmp/x\").read()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea88f706",
   "metadata": {},
   "source": [
    "### Run your training package on Cloud AI Platform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d261765",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "# Output directory and jobID\n",
    "OUTDIR=gs://${BUCKET}/taxifare/trained_model_$(date -u +%y%m%d_%H%M%S)\n",
    "JOBID=taxifare_$(date -u +%y%m%d_%H%M%S)\n",
    "echo ${OUTDIR} ${REGION} ${JOBID}\n",
    "gsutil -m rm -rf ${OUTDIR}\n",
    "\n",
    "# Model and training hyperparameters\n",
    "BATCH_SIZE=50\n",
    "NUM_EXAMPLES_TO_TRAIN_ON=100\n",
    "NUM_EVALS=100\n",
    "NBUCKETS=10\n",
    "LR=0.001\n",
    "NNSIZE=\"32 8\"\n",
    "\n",
    "# GCS paths\n",
    "GCS_PROJECT_PATH=gs://$BUCKET/taxifare\n",
    "DATA_PATH=$GCS_PROJECT_PATH/data\n",
    "TRAIN_DATA_PATH=$DATA_PATH/taxi-train*\n",
    "EVAL_DATA_PATH=$DATA_PATH/taxi-valid*\n",
    "\n",
    "gcloud ai-platform jobs submit training $JOBID \\\n",
    "--module-name=trainer.task \\\n",
    "--package-path=taxifare/trainer \\\n",
    "--staging-bucket=gs://$BUCKET \\\n",
    "--python-version=3.7 \\\n",
    "--runtime-version=$TFVERSION \\\n",
    "--region=${REGION} \\\n",
    "-- \\  #여기부터 task.py 파라미터\n",
    "--eval_data_path $EVAL_DATA_PATH \\\n",
    "--output_dir $OUTDIR \\\n",
    "--train_data_path $TRAIN_DATA_PATH \\\n",
    "--batch_size 5 \\\n",
    "--num_examples_to_train_on 100 \\\n",
    "--num_evals 1 \\\n",
    "--nbuckets 10 \\\n",
    "--lr 0.001 \\\n",
    "--nnsize 32 8"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0ca2a88",
   "metadata": {},
   "source": [
    "### Train in docker container"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1626da4",
   "metadata": {},
   "outputs": [],
   "source": [
    "!gcloud auth configure-docker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2612182",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash \n",
    "\n",
    "PROJECT_DIR=$(cd ./taxifare && pwd)\n",
    "PROJECT_ID=$(gcloud config list project --format \"value(core.project)\")\n",
    "IMAGE_NAME=taxifare_training_container\n",
    "DOCKERFILE=$PROJECT_DIR/Dockerfile\n",
    "IMAGE_URI=gcr.io/$PROJECT_ID/$IMAGE_NAME\n",
    "\n",
    "docker build $PROJECT_DIR -f $DOCKERFILE -t $IMAGE_URI\n",
    "\n",
    "docker push $IMAGE_URI"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "688364b9",
   "metadata": {},
   "source": [
    "### using cloudml-hypertune"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ace60b1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install cloudml-hypertune\n",
    "import hypertune"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7ba3b57",
   "metadata": {},
   "outputs": [],
   "source": [
    "# setting hypertune in source code\n",
    "# add this code after fitting model\n",
    "hp_metric = history.history['val_rmse'][num_evals-1]  # 최종 epoch 실행 후 rmse 값을 metric으로 설정\n",
    "hpt = hypertune.HyperTune()\n",
    "hpt.report_hyperparameter_tuning_metric(hyperparameter_metric_tag='rmse', metric_value=hp_metric)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c5863d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# setting hypertune in yaml\n",
    "%%writefile hptuning_config.yaml\n",
    "trainingInput:\n",
    "  scaleTier: BASIC\n",
    "  hyperparameters:\n",
    "    goal: MINIMIZE\n",
    "    maxTrials: 30\n",
    "    maxParallelTrials: 5\n",
    "    hyperparameterMetricTag: rmse\n",
    "    enableTrialEarlyStopping: True\n",
    "    params:\n",
    "    - parameterName: lr\n",
    "      type: DOUBLE\n",
    "      minValue: 0.0001\n",
    "      maxValue: 0.01\n",
    "      scaleType: UNIT_LINEAR_SCALE\n",
    "    - parameterName: nbuckets\n",
    "      type: INTEGER\n",
    "      minValue: 10\n",
    "      maxValue: 100\n",
    "      scaleType: UNIT_LINEAR_SCALE\n",
    "    - parameterName: batch_size\n",
    "      type: INTEGER\n",
    "      minValue: 10\n",
    "      maxValue: 100\n",
    "      scaleType: UNIT_LINEAR_SCALE    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed99bfe5",
   "metadata": {},
   "source": [
    "#### hptune job 실행 중 oom 발생 시 \n",
    "\n",
    "1. params 값을 작게 조정\n",
    "  - 위에서 nbuckets, batch_size가 시스템 리소스와 관련이 높음\n",
    "  - 값을 바꿔가면서 job을 실행해보고 최적값을 도출해야 함\n",
    "2. scaleTier 변경 (https://cloud.google.com/ai-platform/training/docs/machine-types)\n",
    "3. maxParallelTrials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80cb0b2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Submit training job with hyper parameters tunning\n",
    "\n",
    "gcloud ai-platform jobs submit training $JOBID \\\n",
    "    --module-name=trainer.task \\\n",
    "    --package-path=taxifare/trainer \\\n",
    "    --staging-bucket=gs://$BUCKET \\\n",
    "    --python-version=3.7 \\\n",
    "    --runtime-version=$TFVERSION \\\n",
    "    --region=${REGION} \\\n",
    "    --config=hptuning_config.yaml \\   # tunning 설정파일 경로 지정\n",
    "    -- \\\n",
    "    --eval_data_path $EVAL_DATA_PATH \\\n",
    "    --output_dir $OUTDIR \\\n",
    "    --train_data_path $TRAIN_DATA_PATH \\\n",
    "    --batch_size $BATCH_SIZE \\\n",
    "    --num_examples_to_train_on $NUM_EXAMPLES_TO_TRAIN_ON \\\n",
    "    --num_evals $NUM_EVALS \\\n",
    "    --nbuckets $NBUCKETS \\\n",
    "    --lr $LR \\\n",
    "    --nnsize $NNSIZE "
   ]
  }
 ],
 "metadata": {
  "environment": {
   "name": "tf2-gpu.2-1.m69",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/tf2-gpu.2-1:m69"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

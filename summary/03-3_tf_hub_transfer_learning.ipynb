{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "eca54c95",
   "metadata": {},
   "source": [
    "# 3_tf_hub_transfer_learning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3d7a668",
   "metadata": {},
   "source": [
    "training-data-analyst/courses/machine_learning/deepdive2/image_classification/labs/3_tf_hub_transfer_learning.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5902cbb8",
   "metadata": {},
   "source": [
    "Keras has some convenient methods to read in image data. For instance [tf.keras.preprocessing.image.ImageDataGenerator](https://www.tensorflow.org/api_docs/python/tf/keras/preprocessing/image/ImageDataGenerator) is great for small local datasets. A tutorial on how to use it can be found [here](https://www.tensorflow.org/tutorials/load_data/images), but what if we have so many images, it doesn't fit on a local machine? We can use [tf.data.datasets](https://www.tensorflow.org/api_docs/python/tf/data/Dataset) to build a generator based on files in a Google Cloud Storage Bucket."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe2a79fb",
   "metadata": {},
   "source": [
    "### get image files from googleapi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4a1dd41",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = tf.keras.utils.get_file(\n",
    "    'flower_photos',\n",
    "    'https://storage.googleapis.com/download.tensorflow.org/example_images/flower_photos.tgz',\n",
    "    untar=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c08a991b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://docs.python.org/3/library/pathlib.html#basic-use\n",
    "data_dir = pathlib.Path(data_dir)\n",
    "\n",
    "# https://docs.python.org/3/library/pathlib.html#pathlib.Path.glob\n",
    "data_dir.glob('*/*.jpg')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fe3fa61",
   "metadata": {},
   "source": [
    "### decode image and csv using tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "839a640c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def decode_img(img, reshape_dims):\n",
    "    # Convert the compressed string to a 3D uint8 tensor.\n",
    "    img = tf.image.decode_jpeg(img, channels=IMG_CHANNELS)\n",
    "    # Use `convert_image_dtype` to convert to floats in the [0,1] range.\n",
    "    img = tf.image.convert_image_dtype(img, tf.float32)\n",
    "    # Resize the image to the desired size.\n",
    "    return tf.image.resize(img, reshape_dims)\n",
    "\n",
    "def decode_csv(csv_row):\n",
    "    record_defaults = [\"path\", \"flower\"]\n",
    "    filename, label_string = tf.io.decode_csv(csv_row, record_defaults)\n",
    "    image_bytes = tf.io.read_file(filename=filename)\n",
    "    label = tf.math.equal(CLASS_NAMES, label_string)\n",
    "    return image_bytes, label"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b95c63d9",
   "metadata": {},
   "source": [
    "### image augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7eb4a18a",
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_DELTA = 63.0 / 255.0  # Change brightness by at most 17.7%\n",
    "CONTRAST_LOWER = 0.2\n",
    "CONTRAST_UPPER = 1.8\n",
    "\n",
    "def read_and_preprocess(image_bytes, label, random_augment=False):\n",
    "    if random_augment:\n",
    "        img = decode_img(image_bytes, [IMG_HEIGHT + 10, IMG_WIDTH + 10])\n",
    "        img = tf.image.random_crop(img, (IMG_HEIGHT, IMG_WIDTH, 3))\n",
    "        img = tf.image.random_flip_left_right(img)\n",
    "        img = tf.image.random_brightness(img, MAX_DELTA)\n",
    "        img = tf.image.random_contrast(img, CONTRAST_LOWER, CONTRAST_UPPER)\n",
    "    else:\n",
    "        img = decode_img(image_bytes, [IMG_WIDTH, IMG_HEIGHT])\n",
    "    return img, label"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f919797a",
   "metadata": {},
   "source": [
    "### create dataset from csv file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fb980dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_dataset(csv_of_filenames, batch_size, training=True):\n",
    "    dataset = tf.data.TextLineDataset(filenames=csv_of_filenames) \\\n",
    "        .map(decode_csv).cache()\n",
    "\n",
    "    if training:\n",
    "        dataset = dataset \\\n",
    "            .map(read_and_preprocess_with_augment) \\\n",
    "            .shuffle(SHUFFLE_BUFFER) \\\n",
    "            .repeat(count=None)  # Indefinately.\n",
    "    else:\n",
    "        dataset = dataset \\\n",
    "            .map(read_and_preprocess) \\\n",
    "            .repeat(count=1)  # Each photo used once.\n",
    "\n",
    "    # Prefetch prepares the next set of batches while current batch is in use.\n",
    "    return dataset.batch(batch_size=batch_size).prefetch(buffer_size=AUTOTUNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99ff3766",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test code\n",
    "\n",
    "train_path = \"gs://cloud-ml-data/img/flower_photos/train_set.csv\"\n",
    "train_data = load_dataset(train_path, 1)\n",
    "itr = iter(train_data)\n",
    "\n",
    "image_batch, label_batch = next(itr)\n",
    "img = image_batch[0]\n",
    "plt.imshow(img)\n",
    "print(label_batch[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c49999a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1757c836",
   "metadata": {},
   "outputs": [],
   "source": [
    "module_selection = \"mobilenet_v2_100_224\"\n",
    "module_handle = \"https://tfhub.dev/google/imagenet/{}/feature_vector/4\" \\\n",
    "    .format(module_selection)\n",
    "\n",
    "import tensorflow_hub as hub\n",
    "keras_layer = hub.KerasLayer(module_handle, trainable=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bed4434d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "91dc88ec",
   "metadata": {},
   "source": [
    "# 4_tpu_training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be847952",
   "metadata": {},
   "source": [
    "training-data-analyst/courses/machine_learning/deepdive2/image_classification/labs/4_tpu_training.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc0d57c9",
   "metadata": {},
   "source": [
    "### define a TPU strategy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67222718",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define a TPU strategy\n",
    "resolver = tf.distribute.cluster_resolver.TPUClusterResolver(args.tpu_address) # TODO: Your code goes here\n",
    "tf.config.experimental_connect_to_cluster(resolver)\n",
    "tf.tpu.experimental.initialize_tpu_system(resolver)\n",
    "strategy = tf.distribute.TPUStrategy(resolver) # TODO: Your code goes here\n",
    "\n",
    "# create model and compile in strategy.scope\n",
    "with strategy.scope():\n",
    "    model.build_model()\n",
    "\n",
    "model.fit()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "588e9d68",
   "metadata": {},
   "source": [
    "### create a TPU and run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c2db4f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# run on google cloud shell\n",
    "gcloud compute tpus execution-groups create \\\n",
    " --name=my-tpu \\\n",
    " --zone=us-central1-a \\\n",
    " --tf-version=2.3.2 \\\n",
    " --machine-type=n1-standard-1 \\\n",
    " --accelerator-type=v3-8\n",
    " \n",
    "# then automatically be logged in the TPU shell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31dcc01c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# run in TPU\n",
    "export TPU_NAME=my-tpu\n",
    "python3 -m tpu_models.trainer.task \\\n",
    "    --tpu_address=$TPU_NAME \\\n",
    "    --hub_path=gs://$BUCKET/tpu_models \\\n",
    "    --job-dir=gs://$BUCKET/flowers_tpu_$(date -u +%y%m%d_%H%M%S)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86af2d53",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "262d64f7",
   "metadata": {},
   "source": [
    "# 2_mnist_models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7805afdc",
   "metadata": {},
   "source": [
    "training-data-analyst/courses/machine_learning/deepdive2/image_classification/labs/2_mnist_models.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ab0ff5a",
   "metadata": {},
   "source": [
    "### Scales images from a 0-255 int range to a 0-1 float range"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df0b92c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def scale(image, label):\n",
    "    \"\"\"Scales images from a 0-255 int range to a 0-1 float range\"\"\"\n",
    "    image = tf.cast(image, tf.float32)\n",
    "    image /= 255\n",
    "    image = tf.expand_dims(image, -1)\n",
    "    return image, label"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d4002e2",
   "metadata": {},
   "source": [
    "### Loads MNIST dataset into a tf.data.Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec188161",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_dataset(\n",
    "        data, training=True, buffer_size=5000, batch_size=100, nclasses=10):\n",
    "    \"\"\"Loads MNIST dataset into a tf.data.Dataset\"\"\"\n",
    "    (x_train, y_train), (x_test, y_test) = data\n",
    "    x = x_train if training else x_test\n",
    "    y = y_train if training else y_test\n",
    "    # One-hot encode the classes\n",
    "    y = tf.keras.utils.to_categorical(y, nclasses)\n",
    "    dataset = tf.data.Dataset.from_tensor_slices((x, y))\n",
    "    dataset = dataset.map(scale).batch(batch_size)\n",
    "    if training:\n",
    "        dataset = dataset.shuffle(buffer_size).repeat()\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cbe6d38",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "9714ec1c",
   "metadata": {},
   "source": [
    "# 1_mnist_linear"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5033c019",
   "metadata": {},
   "source": [
    "training-data-analyst/courses/machine_learning/deepdive2/image_classification/labs/1_mnist_linear.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d535bd63",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data from mnist \n",
    "# train/test values are numpy ndarray objects\n",
    "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.mnist.load_data()\n",
    "\n",
    "# get the number of classes\n",
    "NCLASSES = tf.size(tf.unique(y_train).y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "269d2025",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot numpy ndarray objects \n",
    "import matplotlib.pyplot as plt\n",
    "plt.imshow(x_test[IMGNO].reshape(HEIGHT, WIDTH))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3372d09e",
   "metadata": {},
   "source": [
    "### One-hot encode the classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba4a270c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "y = tf.keras.utils.to_categorical(y, NCLASSES)"
   ]
  }
 ],
 "metadata": {
  "environment": {
   "name": "tf2-gpu.2-1.m69",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/tf2-gpu.2-1:m69"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
